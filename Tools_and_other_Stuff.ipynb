{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tools and other Stuff.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jqsjBq-hju_B",
        "mvFjZj7_jxbh",
        "pCbjg1OLkl_7",
        "7-mnWUimB5BV",
        "7GJkp_OmmRKQ",
        "jOAJEpTvvQ8p",
        "22_UmVyXu-yu",
        "CA0Opfy5vEye",
        "ATrfiFwqJ9OZ"
      ],
      "authorship_tag": "ABX9TyPdAzkYiIB2ngpxBZnf7x/O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/horsinnaround/Data-Science-Tools/blob/main/Tools_and_other_Stuff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing"
      ],
      "metadata": {
        "id": "jqsjBq-hju_B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUER3xubjoIp"
      },
      "outputs": [],
      "source": [
        "from io import StringIO\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import chi2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import zipfile\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from numpy import array\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB \n",
        "!pip install catboost\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier \n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "import seaborn as sns\n",
        "from time import time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All the way with texts"
      ],
      "metadata": {
        "id": "ZdRZUr-TkesQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text to int\n",
        "\n",
        "for changing dtype of data frame columns to serial or factorize them or make strings ti ints"
      ],
      "metadata": {
        "id": "mvFjZj7_jxbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_ = put dataframe here\n",
        "str_to_fac=[]\n",
        "for i in range(len(df.dtypes)):\n",
        "    if df.dtypes[i] == 'object':\n",
        "        to_fac = df[df.columns[i]].factorize()\n",
        "        str_to_fac.append(to_fac)\n",
        "        df_[f'{df.columns[i]}'] = to_fac[0]"
      ],
      "metadata": {
        "id": "MekxJW8ckA3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text to vector"
      ],
      "metadata": {
        "id": "pCbjg1OLkl_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text to vector\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# text is the column that you have the sentense\n",
        "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
        "features = tfidf.fit_transform(df.text).toarray()\n",
        "labels = df.category_id\n",
        "features.shape"
      ],
      "metadata": {
        "id": "qEJKMl3PlFxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regular ml"
      ],
      "metadata": {
        "id": "jjMQa-XokrjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## classification with different data sample number"
      ],
      "metadata": {
        "id": "7-mnWUimB5BV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Learning curve:\n",
        "\n",
        "scores_list = []\n",
        "\n",
        "clf = CatBoostClassifier()\n",
        "# clf = SVC()\n",
        "\n",
        "def loss_func(Y_true, Y_prediction): # definig a loss function\n",
        "    return (1 - accuracy_score(Y_true, Y_prediction))\n",
        "\n",
        "ns_list = [1000,5000,9000,13000,19000,25000] # number of samples that we want to keep\n",
        "n_avg = 1  # Number of times to average over\n",
        "\n",
        "labels = list(df['category_id'])\n",
        "for ns in ns_list:   # For different number of samples, we try training our estimator\n",
        "    print(f\"for {ns} number of data\")        \n",
        "\n",
        "    e_in = 0\n",
        "    e_out = 0   # For each, we record the in and out score. \n",
        "    for i in range(n_avg):\n",
        "        X_train, X_test, Y_train, Y_test = train_test_split(features[0:ns],labels[0:ns], random_state = 0)\n",
        "\n",
        "        clf.fit( X_train , Y_train )\n",
        "\n",
        "        e_in  += loss_func( Y_train, clf.predict(X_train ) ) # in-sample error\n",
        "        e_out += loss_func( Y_test , clf.predict(X_test )  ) # out-sample error\n",
        "\n",
        "    scores_list += [[e_in/n_avg, e_out/n_avg]]\n",
        "\n",
        "    \n",
        "scores_list = array(scores_list)  \n",
        "\n",
        "xlabel = 'Training samples'\n",
        "ylabel = 'loss'\n",
        "plt_title = 'Learning curve for classification data \\n using a CatBoost Classifier'\n",
        "fig = plt.figure(figsize=(8,6),dpi=300)\n",
        "ax2 = fig.add_subplot(111, xlabel=xlabel, ylabel=ylabel, title=plt_title)\n",
        "ax2.plot(ns_list, scores_list[:,0], '-o',label = 'Training Score')\n",
        "ax2.plot(ns_list, scores_list[:,1], '-o',label = 'Validation Score')\n",
        "ax2.legend()\n",
        "plt.savefig('learning curve.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "awArtkorkzZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ukFYUioiB4sW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZImWrutvB4pJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-0xeSWqDB4kI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mHxwaYbHB4cw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vQVveQdsB4Un"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3pYXTQ-7B4LU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XeBxIXBjB3-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xS2KKLfxlpfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "ZJYUyfL6mOO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## remove data with very low sample"
      ],
      "metadata": {
        "id": "n449thL9NXbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = df_p.drop('labels',axis=1)\n",
        "labels = df_p['labels']\n",
        "labels_t = Counter(labels)\n",
        "print('Original dataset shape %s' % Counter(labels))\n",
        "drop_dead = []\n",
        "for lab in labels_t.keys():\n",
        "    if len(df[df['labels']==lab])<300:\n",
        "        drop_dead.append(lab)\n",
        "        df.drop(index=df[df['labels']==lab].index,inplace=True)\n",
        "print('Final dataset shape %s' % Counter(labels))"
      ],
      "metadata": {
        "id": "9ld4a8M9NbJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## change labels in dataframe"
      ],
      "metadata": {
        "id": "GJUeObtdeGWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = df[df.labels!='normal'].index\n",
        "df.loc[index] = 'nep'"
      ],
      "metadata": {
        "id": "joUXgfQzeJbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## zip unzipping"
      ],
      "metadata": {
        "id": "7GJkp_OmmRKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzipping\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/A/hamed thesis/kdd_test.csv.zip', \"r\")\n",
        "zip_ref.extractall('/content/drive/MyDrive/A/hamed thesis/')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "Kyx9ZKDHmT9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA"
      ],
      "metadata": {
        "id": "jOAJEpTvvQ8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=100, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto',random_state=None)\n",
        "features = pca.fit_transform(features)\n",
        "features.shape"
      ],
      "metadata": {
        "id": "-x0h9g1BvTl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## barplot"
      ],
      "metadata": {
        "id": "22_UmVyXu-yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count Plot (a.k.a. Bar Plot)\n",
        "plt.figure(figsize=(9,6),dpi=200)\n",
        "sns.countplot(y='labels', data=df_)\n",
        "# plt.xticks(rotation=-90)"
      ],
      "metadata": {
        "id": "JIF8NRa1vB4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cor plot"
      ],
      "metadata": {
        "id": "CA0Opfy5vEye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr = df_.corr();\n",
        "plt.figure(figsize=(9,9),dpi=100);\n",
        "# sns.heatmap(corr,linewidths=.5);\n",
        "sns.heatmap(corr);\n",
        "\n",
        "plt.xticks(rotation=-90);\n",
        "plt.yticks(rotation=0);"
      ],
      "metadata": {
        "id": "lmmBv_TnvHEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Smothe"
      ],
      "metadata": {
        "id": "ATrfiFwqJ9OZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SVMSMOTE \n",
        "print('Original dataset shape %s' % Counter(y))\n",
        "sm = SVMSMOTE(sampling_strategy='auto', \n",
        "              random_state=1, \n",
        "              k_neighbors=5, \n",
        "              n_jobs=None, \n",
        "              m_neighbors=10, \n",
        "              svm_estimator=None,\n",
        "              out_step=0.5)\n",
        "X_t, y_t = sm.fit_resample(X_t, y_t)\n",
        "print('Resampled dataset shape %s' % Counter(y_t))"
      ],
      "metadata": {
        "id": "skQ8vgaKKCgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test classification"
      ],
      "metadata": {
        "id": "cFiTMnXvJ-NO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_classes=2, class_sep=2,\n",
        "weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,\n",
        "n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\n",
        "print('Original dataset shape %s' % Counter(y))\n",
        "print('Resampled dataset shape %s' % Counter(y_t))"
      ],
      "metadata": {
        "id": "ZUHB1-3PKRwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KZHMYbG6J-p0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5UOiwo62J-_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YpibhljXJ_Vg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MXv_53CXNUyR"
      }
    }
  ]
}