{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tools and other Stuff.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZdRZUr-TkesQ",
        "mvFjZj7_jxbh",
        "pCbjg1OLkl_7",
        "jjMQa-XokrjF",
        "7-mnWUimB5BV",
        "ukFYUioiB4sW",
        "7GJkp_OmmRKQ",
        "jOAJEpTvvQ8p",
        "ATrfiFwqJ9OZ"
      ],
      "authorship_tag": "ABX9TyOjJW+n1P7gQ14pPkNXd1Yl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/horsinnaround/Data-Science-Tools/blob/main/Tools_and_other_Stuff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing"
      ],
      "metadata": {
        "id": "jqsjBq-hju_B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUER3xubjoIp"
      },
      "outputs": [],
      "source": [
        "from io import StringIO\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import chi2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import zipfile\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from numpy import array\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB \n",
        "!pip install catboost\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier \n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "import seaborn as sns\n",
        "from time import time\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All the way with texts"
      ],
      "metadata": {
        "id": "ZdRZUr-TkesQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text to int\n",
        "\n",
        "for changing dtype of data frame columns to serial or factorize them or make strings ti ints"
      ],
      "metadata": {
        "id": "mvFjZj7_jxbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_ = put dataframe here\n",
        "str_to_fac=[]\n",
        "for i in range(len(df.dtypes)):\n",
        "    if df.dtypes[i] == 'object':\n",
        "        to_fac = df[df.columns[i]].factorize()\n",
        "        str_to_fac.append(to_fac)\n",
        "        df_[f'{df.columns[i]}'] = to_fac[0]"
      ],
      "metadata": {
        "id": "MekxJW8ckA3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text to vector"
      ],
      "metadata": {
        "id": "pCbjg1OLkl_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text to vector\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# text is the column that you have the sentense\n",
        "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
        "features = tfidf.fit_transform(df.text).toarray()\n",
        "labels = df.category_id\n",
        "features.shape"
      ],
      "metadata": {
        "id": "qEJKMl3PlFxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regular ml"
      ],
      "metadata": {
        "id": "jjMQa-XokrjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## classification with different data sample number"
      ],
      "metadata": {
        "id": "7-mnWUimB5BV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Learning curve:\n",
        "\n",
        "scores_list = []\n",
        "\n",
        "clf = CatBoostClassifier()\n",
        "# clf = SVC()\n",
        "\n",
        "def loss_func(Y_true, Y_prediction): # definig a loss function\n",
        "    return (1 - accuracy_score(Y_true, Y_prediction))\n",
        "\n",
        "ns_list = [1000,5000,9000,13000,19000,25000] # number of samples that we want to keep\n",
        "n_avg = 1  # Number of times to average over\n",
        "\n",
        "labels = list(df['category_id'])\n",
        "for ns in ns_list:   # For different number of samples, we try training our estimator\n",
        "    print(f\"for {ns} number of data\")        \n",
        "\n",
        "    e_in = 0\n",
        "    e_out = 0   # For each, we record the in and out score. \n",
        "    for i in range(n_avg):\n",
        "        X_train, X_test, Y_train, Y_test = train_test_split(features[0:ns],labels[0:ns], random_state = 0)\n",
        "\n",
        "        clf.fit( X_train , Y_train )\n",
        "\n",
        "        e_in  += loss_func( Y_train, clf.predict(X_train ) ) # in-sample error\n",
        "        e_out += loss_func( Y_test , clf.predict(X_test )  ) # out-sample error\n",
        "\n",
        "    scores_list += [[e_in/n_avg, e_out/n_avg]]\n",
        "\n",
        "    \n",
        "scores_list = array(scores_list)  \n",
        "\n",
        "xlabel = 'Training samples'\n",
        "ylabel = 'loss'\n",
        "plt_title = 'Learning curve for classification data \\n using a CatBoost Classifier'\n",
        "fig = plt.figure(figsize=(8,6),dpi=300)\n",
        "ax2 = fig.add_subplot(111, xlabel=xlabel, ylabel=ylabel, title=plt_title)\n",
        "ax2.plot(ns_list, scores_list[:,0], '-o',label = 'Training Score')\n",
        "ax2.plot(ns_list, scores_list[:,1], '-o',label = 'Validation Score')\n",
        "ax2.legend()\n",
        "plt.savefig('learning curve.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "awArtkorkzZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## simply test"
      ],
      "metadata": {
        "id": "ukFYUioiB4sW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "# ns_list = [1000,5000,9000,13000,19000] # number of samples that we want to keep\n",
        "n_avg = 3 # Number of times to average over\n",
        "duration_fit_list=[]\n",
        "duration_pred_list=[]\n",
        "accuracy_score_list=[]\n",
        "weighted_precision_score_list=[]\n",
        "weighted_recall_score_list=[]\n",
        "weighted_f1_score_list=[]\n",
        "entries = []\n",
        "clf = SVC()\n",
        "duration_fit=0\n",
        "duration_pred=0\n",
        "accuracy_scores = 0\n",
        "weighted_precision_scores = 0\n",
        "weighted_recall_scores = 0\n",
        "weighted_f1_scores = 0\n",
        "# print(\"4\")\n",
        "featuresT,features_,labelsT,labels_ = train_test_split(features,labels)\n",
        "e_in = 0\n",
        "e_out = 0   # For each, we record the in and out score. \n",
        "for i in range(n_avg):\n",
        "    \n",
        "    start_fit = time()\n",
        "    clf.fit(X = featuresT, y = labelsT)\n",
        "    end_fit = time()\n",
        "    duration_fit += end_fit - start_fit # time duration for fitting\n",
        "    \n",
        "    start_pred = time()\n",
        "    y_prime = clf.predict(features_)\n",
        "    end_pred = time()\n",
        "    duration_pred += end_pred - start_pred # time duration for predicting\n",
        "    \n",
        "    accuracy_scores += round(accuracy_score(y_prime,labels_), 4)\n",
        "    weighted_precision_scores += round(precision_score(y_prime,labels_, average='weighted',zero_division=1), 4)\n",
        "    weighted_recall_scores += round(recall_score(y_prime,labels_, average='weighted'), 4)\n",
        "    weighted_f1_scores += round(f1_score(y_prime,labels_, average='weighted'), 4)\n",
        "duration_fit_list.append(duration_fit/n_avg)\n",
        "duration_pred_list.append(duration_pred/n_avg)\n",
        "accuracy_score_list.append(accuracy_scores/n_avg)\n",
        "weighted_precision_score_list.append(weighted_precision_scores/n_avg)\n",
        "weighted_recall_score_list.append(weighted_recall_scores/n_avg)\n",
        "weighted_f1_score_list.append(weighted_f1_scores/n_avg)\n",
        "\n",
        "\n",
        "report_data = pd.DataFrame(['SVC'], columns=['model'])\n",
        "report_data['fit_duration'] = duration_fit_list\n",
        "report_data['pred_duration'] = duration_pred_list\n",
        "report_data['accuracy'] = accuracy_score_list\n",
        "report_data['weighted_precision'] = weighted_precision_score_list\n",
        "report_data['weighted_recall'] = weighted_recall_score_list\n",
        "report_data['weighted_f1_score'] = weighted_f1_score_list\n",
        "\n",
        "# report_data.to_excel(f'/content/drive/MyDrive/data/{folder}/Scores_for_all_models_smote.xlsx')"
      ],
      "metadata": {
        "id": "aQ1XtYEK7YGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cross validation"
      ],
      "metadata": {
        "id": "wnJ9r0KFfoCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_list = [\n",
        "    RandomForestClassifier(n_estimators=100, max_depth=6, random_state=0, max_features=30),\n",
        "    LinearSVC(),\n",
        "    MultinomialNB(),\n",
        "    SVC(),\n",
        "    MLPClassifier(max_iter=500,early_stopping=True),\n",
        "    XGBClassifier(),\n",
        "    CatBoostClassifier(verbose=0),\n",
        "    LogisticRegression(random_state=0,max_iter=1000),\n",
        "]\n",
        "\n",
        "CV = 3\n",
        "cv_df = pd.DataFrame(index=range(CV * len(model_list)))\n",
        "entries = []\n",
        "for model in model_list:\n",
        "  print(model)\n",
        "  model_name = model.__class__.__name__\n",
        "  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
        "  for fold_idx, accuracy in enumerate(accuracies):\n",
        "    entries.append((model_name, fold_idx, accuracy))\n",
        "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
        "import seaborn as sns\n",
        "# plt.figure(dpi=150)\n",
        "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
        "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
        "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sa9EFMwBfqnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZImWrutvB4pJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-0xeSWqDB4kI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mHxwaYbHB4cw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vQVveQdsB4Un"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3pYXTQ-7B4LU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XeBxIXBjB3-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xS2KKLfxlpfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uZuBoN1D7TNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "ZJYUyfL6mOO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing required modules\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "compression = zipfile.ZIP_DEFLATED\n",
        "def get_all_file_paths(directory):\n",
        "\n",
        "\t# initializing empty file paths list\n",
        "\tfile_paths = []\n",
        "\n",
        "\t# crawling through directory and subdirectories\n",
        "\tfor root, directories, files in os.walk(directory):\n",
        "\t\tfor filename in files:\n",
        "\t\t\t# join the two strings in order to form the full filepath.\n",
        "\t\t\tfilepath = os.path.join(root, filename)\n",
        "\t\t\tfile_paths.append(filepath)\n",
        "\n",
        "\t# returning all file paths\n",
        "\treturn file_paths\t\t\n",
        "\n",
        "def main():\n",
        "\t# path to folder which needs to be zipped\n",
        "\tdirectory = '/content/results'\n",
        "\n",
        "\t# calling function to get all file paths in the directory\n",
        "\tfile_paths = get_all_file_paths(directory)\n",
        "\n",
        "\t# printing the list of all files to be zipped\n",
        "\tprint('Following files will be zipped:')\n",
        "\tfor file_name in file_paths:\n",
        "\t\tprint(file_name)\n",
        "\n",
        "\t# writing files to a zipfile\n",
        "\twith ZipFile('/content/drive/MyDrive/A Work/my_python_files.zip','w') as zip:\n",
        "\t\t# writing each file one by one\n",
        "\t\tfor file in file_paths:\n",
        "\t\t\tzip.write(file,compress_type=compression)\n",
        "\n",
        "\tprint('All files zipped successfully!')\t\t\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tmain()\n"
      ],
      "metadata": {
        "id": "Ovm5cJA6FVRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## remove data with very low sample"
      ],
      "metadata": {
        "id": "n449thL9NXbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = df_p.drop('labels',axis=1)\n",
        "labels = df_p['labels']\n",
        "labels_t = Counter(labels)\n",
        "print('Original dataset shape %s' % Counter(labels))\n",
        "drop_dead = []\n",
        "for lab in labels_t.keys():\n",
        "    if len(df[df['labels']==lab])<300:\n",
        "        drop_dead.append(lab)\n",
        "        df.drop(index=df[df['labels']==lab].index,inplace=True)\n",
        "print('Final dataset shape %s' % Counter(labels))"
      ],
      "metadata": {
        "id": "9ld4a8M9NbJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## svm smoth"
      ],
      "metadata": {
        "id": "4LYadj-FWPJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SVMSMOTE \n",
        "from imblearn.over_sampling import SVMSMOTE ,SMOTENC,ADASYN,KMeansSMOTE,BorderlineSMOTE\n",
        "from imblearn.under_sampling import AllKNN,NearMiss\n",
        "sm = SVMSMOTE(sampling_strategy='auto', \n",
        "              random_state=3, \n",
        "              k_neighbors=5, \n",
        "              n_jobs=None, \n",
        "              m_neighbors=10, \n",
        "              svm_estimator=None,\n",
        "              out_step=0.5)\n",
        "features, labels = sm.fit_resample(features, labels)"
      ],
      "metadata": {
        "id": "ZcCa0_1wWSXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## change labels in dataframe"
      ],
      "metadata": {
        "id": "GJUeObtdeGWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = df[df.labels!='normal'].index\n",
        "df.loc[index] = 'nep'"
      ],
      "metadata": {
        "id": "joUXgfQzeJbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## zip unzipping"
      ],
      "metadata": {
        "id": "7GJkp_OmmRKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzipping\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/A/hamed thesis/kdd_test.csv.zip', \"r\")\n",
        "zip_ref.extractall('/content/drive/MyDrive/A/hamed thesis/')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "Kyx9ZKDHmT9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA"
      ],
      "metadata": {
        "id": "jOAJEpTvvQ8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=100, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto',random_state=None)\n",
        "features = pca.fit_transform(features)\n",
        "features.shape"
      ],
      "metadata": {
        "id": "-x0h9g1BvTl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## barplot"
      ],
      "metadata": {
        "id": "22_UmVyXu-yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count Plot (a.k.a. Bar Plot)\n",
        "plt.figure(figsize=(9,6),dpi=200)\n",
        "sns.countplot(y='labels', data=df_)\n",
        "# plt.xticks(rotation=-90)"
      ],
      "metadata": {
        "id": "JIF8NRa1vB4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cor plot"
      ],
      "metadata": {
        "id": "CA0Opfy5vEye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr = df_.corr();\n",
        "plt.figure(figsize=(9,9),dpi=100);\n",
        "# sns.heatmap(corr,linewidths=.5);\n",
        "sns.heatmap(corr);\n",
        "\n",
        "plt.xticks(rotation=-90);\n",
        "plt.yticks(rotation=0);"
      ],
      "metadata": {
        "id": "lmmBv_TnvHEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Smothe"
      ],
      "metadata": {
        "id": "ATrfiFwqJ9OZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SVMSMOTE \n",
        "print('Original dataset shape %s' % Counter(y))\n",
        "sm = SVMSMOTE(sampling_strategy='auto', \n",
        "              random_state=1, \n",
        "              k_neighbors=5, \n",
        "              n_jobs=None, \n",
        "              m_neighbors=10, \n",
        "              svm_estimator=None,\n",
        "              out_step=0.5)\n",
        "X_t, y_t = sm.fit_resample(X_t, y_t)\n",
        "print('Resampled dataset shape %s' % Counter(y_t))"
      ],
      "metadata": {
        "id": "skQ8vgaKKCgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test classification"
      ],
      "metadata": {
        "id": "cFiTMnXvJ-NO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_classes=2, class_sep=2,\n",
        "weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,\n",
        "n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\n",
        "print('Original dataset shape %s' % Counter(y))\n",
        "print('Resampled dataset shape %s' % Counter(y_t))"
      ],
      "metadata": {
        "id": "ZUHB1-3PKRwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## kfold"
      ],
      "metadata": {
        "id": "eL53uL_UkSwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import SVMSMOTE \n",
        "k_fold = KFold(n_splits=5,shuffle=True, random_state=2)\n",
        "\n",
        "# sm = SVMSMOTE(sampling_strategy='auto', \n",
        "#               random_state=1, \n",
        "#               k_neighbors=5, \n",
        "#               n_jobs=None, \n",
        "#               m_neighbors=10, \n",
        "#               svm_estimator=None,\n",
        "#               out_step=0.5)\n",
        "# features, labels = sm.fit_resample(features, labels)\n",
        "dataaa = []\n",
        "p = 0\n",
        "ll = 0\n",
        "for train_indices, test_indices in k_fold.split(features, labels ):\n",
        "\n",
        "    dataaa.append((p,(train_indices, test_indices)))\n",
        "\n",
        "    print('Train: %s | test: %s' % (len(train_indices), len(test_indices)))\n",
        "    X_t, y_t, X_, y_  = features.iloc[train_indices],labels.iloc[train_indices],features.iloc[test_indices],labels.iloc[test_indices]\n",
        "\n",
        "    # clf = XGBClassifier()\n",
        "    clf = LogisticRegression()\n",
        "    clf.fit(X = X_t, y = y_t)\n",
        "    y_pred = clf.predict(X_)\n",
        "    print(p, metrics.accuracy_score(y_,y_pred))\n",
        "    p = p + 1\n",
        "    ll = ll + metrics.accuracy_score(y_,y_pred)\n",
        "        # print(i,classification_report(y_,y_pred))\n",
        "\n",
        "ll / (p)"
      ],
      "metadata": {
        "id": "JrlX8wjukU6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross vaidation Root"
      ],
      "metadata": {
        "id": "1bl3J4cJCVlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_list = [\n",
        "    RandomForestClassifier(random_state= random_state),\n",
        "    LinearSVC(),\n",
        "    # # MultinomialNB(),\n",
        "    DecisionTreeClassifier(random_state= random_state),\n",
        "    SVC(),\n",
        "    MLPClassifier(),\n",
        "    XGBClassifier(random_state= random_state),\n",
        "    # # CatBoostClassifier(verbose=0),\n",
        "    LogisticRegression(random_state= random_state),\n",
        "]\n",
        "\n",
        "\n",
        "cv_df = pd.DataFrame(index=range(CV * len(model_list)))\n",
        "entries = []\n",
        "entriesOne = []\n",
        "scors = ['accuracy', 'precision', 'recall', 'f1','roc_auc']\n",
        "for model in model_list:\n",
        "  print(model)\n",
        "  model_name = model.__class__.__name__\n",
        "  accuracies = cross_validate(model, features, labels, scoring=scors ,return_train_score=True, cv=k_fold)\n",
        "  cl = list(accuracies.keys())\n",
        "\n",
        "  enteryOne = [model_name]\n",
        "  [enteryOne.append(accuracies[cl[i]].mean()) for i in range(len(cl))]\n",
        "  entriesOne.append(enteryOne)\n",
        "\n",
        "\n",
        "  for fold_idx in range(CV):\n",
        "    entery = [model_name,fold_idx+1]\n",
        "    [entery.append(accuracies[cl[i]][fold_idx]) for i in range(len(cl))]\n",
        "    entries.append(entery)\n",
        "clm =['model name','index fold']\n",
        "clmOne =['model name']\n",
        "[clm.append(i) for i in cl]\n",
        "clm\n",
        "[clmOne.append(i) for i in cl]\n",
        "clmOne\n",
        "cv_df = pd.DataFrame(entries, columns=clm)\n",
        "cv_dfOne = pd.DataFrame(entriesOne, columns=clmOne)\n",
        "clear_output()\n",
        "# entries"
      ],
      "metadata": {
        "id": "cT-ouCUXCZAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "# sklearn.metrics.SCORERS.keys()\n"
      ],
      "metadata": {
        "id": "SUizhfgeGeNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KZHMYbG6J-p0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5UOiwo62J-_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YpibhljXJ_Vg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MXv_53CXNUyR"
      }
    }
  ]
}